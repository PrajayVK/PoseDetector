{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, min_detection_confidence=0.5)\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    keypoints = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            keypoints.append(np.array([[lmk.x, lmk.y] for lmk in results.pose_landmarks.landmark]).flatten())\n",
    "\n",
    "    cap.release()\n",
    "    return np.mean(keypoints, axis=0) if keypoints else None\n",
    "\n",
    "def extract_keypoints_from_videos(videos_folder, label):\n",
    "    keypoints = []\n",
    "    labels = []\n",
    "\n",
    "    for video_file in os.listdir(videos_folder):\n",
    "        video_path = os.path.join(videos_folder, video_file)\n",
    "        video_keypoints = process_video(video_path)\n",
    "\n",
    "        if video_keypoints is not None:\n",
    "            keypoints.append(video_keypoints)\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(keypoints), np.array(labels)\n",
    "\n",
    "# Paths to your video folders\n",
    "correct_videos_folder = './Correct sequence'\n",
    "incorrect_videos_folder = './Wrong sequence'\n",
    "\n",
    "# Extract keypoints\n",
    "correct_keypoints, correct_labels = extract_keypoints_from_videos(correct_videos_folder, 1)  # Label 1 for correct\n",
    "incorrect_keypoints, incorrect_labels = extract_keypoints_from_videos(incorrect_videos_folder, 0)  # Label 0 for incorrect\n",
    "\n",
    "# Combine data\n",
    "all_keypoints = np.concatenate([correct_keypoints, incorrect_keypoints])\n",
    "all_labels = np.concatenate([correct_labels, incorrect_labels])\n",
    "\n",
    "# Save the data\n",
    "with open('keypoints_data.pkl', 'wb') as f:\n",
    "    pickle.dump((all_keypoints, all_labels), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         8\n",
      "           1       0.86      1.00      0.92        12\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.93      0.88      0.89        20\n",
      "weighted avg       0.91      0.90      0.90        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the preprocessed data\n",
    "with open('keypoints_data.pkl', 'rb') as f:\n",
    "    all_keypoints, all_labels = pickle.load(f)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_keypoints, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Save the trained model\n",
    "with open('trained_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the trained model\n",
    "with open('trained_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, min_detection_confidence=0.5)\n",
    "\n",
    "def draw_landmarks(frame, landmarks):\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing.draw_landmarks(frame, landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "def process_and_predict(video_path, model, pose):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            # Draw keypoints\n",
    "            draw_landmarks(frame, results.pose_landmarks)\n",
    "\n",
    "            # Predict\n",
    "            keypoints = np.array([[lmk.x, lmk.y] for lmk in results.pose_landmarks.landmark]).flatten()\n",
    "            avg_keypoints = keypoints.reshape(1, -1)\n",
    "            prediction = model.predict(avg_keypoints)\n",
    "            text = \"Correct\" if prediction[0] == 1 else \"Incorrect\"\n",
    "\n",
    "            # Display prediction\n",
    "            cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Pushup Analysis', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video_path = 'P:/PoseDetector/Push ups/wrong2.mp4'\n",
    "process_and_predict(video_path, loaded_model, pose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit\n"
     ]
    }
   ],
   "source": [
    "def real_time_predict(model, pose):\n",
    "    cap = cv2.VideoCapture(0)  # 0 for the default webcam\n",
    "    print(\"Press 'q' to quit\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            keypoints = np.array([[lmk.x, lmk.y] for lmk in results.pose_landmarks.landmark]).flatten()\n",
    "            avg_keypoints = keypoints.reshape(1, -1)\n",
    "            prediction = model.predict(avg_keypoints)\n",
    "            text = \"Correct\" if prediction[0] == 1 else \"Incorrect\"\n",
    "            cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Pushup Analysis', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage for real-time prediction\n",
    "real_time_predict(loaded_model, pose)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
