{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mouly\\AppData\\Local\\Temp\\ipykernel_10248\\1116652943.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the trained RandomForest model\n",
    "model = joblib.load(\"./new_model_withhip.h5\")\n",
    "\n",
    "# Define a dictionary to convert model output to human-readable labels\n",
    "label_dict = {0: \"Correct\", 1: \"Too High\", 2: \"Too Low\"}\n",
    "\n",
    "# Initialize mediapipe pose class\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)  # 0 is typically the built-in webcam\n",
    "\n",
    "frame_count = 0\n",
    "frame_skip = 9  # this will process every 10th frame\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue  # skip empty frames\n",
    "\n",
    "        # Skip frames to process every 10th frame\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % (frame_skip + 1) != 0:\n",
    "            continue\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform pose detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Draw pose annotations on the image\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Calculate the squat angles if pose landmarks are detected\n",
    "        if results.pose_landmarks:\n",
    "            # Extract landmarks\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            try:\n",
    "                # Calculate knee angle\n",
    "                knee_hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y])\n",
    "                knee_knee = np.array([landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y])\n",
    "                knee_ankle = np.array([landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y])\n",
    "                knee_angle = np.arccos(np.dot((knee_hip - knee_knee), (knee_ankle - knee_knee)) /\n",
    "                                       (np.linalg.norm(knee_hip - knee_knee) * np.linalg.norm(knee_ankle - knee_knee)))\n",
    "                knee_angle = np.degrees(knee_angle)\n",
    "\n",
    "                # Calculate hip angle\n",
    "                hip_shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y])\n",
    "                hip_hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y])\n",
    "                hip_knee = np.array([landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y])\n",
    "                hip_angle = np.arccos(np.dot((hip_shoulder - hip_hip), (hip_knee - hip_hip)) /\n",
    "                                      (np.linalg.norm(hip_shoulder - hip_hip) * np.linalg.norm(hip_knee - hip_hip)))\n",
    "                hip_angle = np.degrees(hip_angle)\n",
    "\n",
    "                new_data = pd.DataFrame({'Knee Angle': [knee_angle], 'Hip Angle': [hip_angle]})\n",
    "\n",
    "        # Predict the posture\n",
    "                prediction = model.predict(new_data)\n",
    "\n",
    "        # Interpret the model's output for knee and hip labels\n",
    "                label = label_dict[prediction[0]]  # Interpretation for knee\n",
    "                  \n",
    "\n",
    "        # Display the predictions and angles on the frame\n",
    "                cv2.rectangle(image, (5, 5), (300, 120), (0, 0, 0), -1)  # Smaller background rectangle\n",
    "\n",
    "                font_scale = 0.7  # Smaller font size\n",
    "                line_thickness = 2\n",
    "                vertical_spacing = 25  # Adjust the vertical spacing between lines\n",
    "\n",
    "                cv2.putText(image, f'Knee Angle: {int(knee_angle)}', (10, 25), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), line_thickness, cv2.LINE_AA)\n",
    "                cv2.putText(image, f'Hip Angle: {int(hip_angle)}', (10, 25 + vertical_spacing), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), line_thickness, cv2.LINE_AA)\n",
    "                cv2.putText(image, f'Label: {label}', (10, 25 + 2 * vertical_spacing), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), line_thickness, cv2.LINE_AA)\n",
    "                \n",
    "\n",
    "            except Exception as e:\n",
    "                # Print any exceptions to the terminal\n",
    "                print(e)\n",
    "                pass  # If there is any error in the landmark detection, ignore it\n",
    "\n",
    "        # Convert the RGB image back to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.namedWindow(\"Squat Posture Evaluation\", cv2.WND_PROP_FULLSCREEN)\n",
    "        cv2.setWindowProperty(\"Squat Posture Evaluation\",cv2.WND_PROP_FULLSCREEN,\n",
    "               cv2.WINDOW_FULLSCREEN)\n",
    "        cv2.imshow('Squat Posture Evaluation', image)\n",
    "\n",
    "        # Press 'q' to break out of the loop\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    # When everything is done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
